{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 以 p51 範例為例子\n",
    "from tensorflow.keras import optimizers, layers, datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "# step1 讀取圖片\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "# 转换为整形张量\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "# one-hot 编码\n",
    "y = tf.one_hot(y, depth=10)\n",
    "\n",
    "print(x.shape)  # (60000, 28, 28)\n",
    "x = tf.reshape(x, [-1, 28 * 28])\n",
    "x = tf.reshape(x, [x.shape[0], -1])  # 等於上面寫法\n",
    "print(x.shape)  # (60000, 784)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "train_dataset = train_dataset.batch(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step2 定義初始化參數\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3 單次epoch訓練\n",
    "def train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001):\n",
    "  for step, (x, y) in enumerate(train_dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "      # 第一层计算， [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b,256] + [b, 256]\n",
    "      h1 = x @ w1 + tf.broadcast_to(b1, (x.shape[0], 256))\n",
    "      h1 = tf.nn.relu(h1)  # 通过激活函数\n",
    "\n",
    "      # 第二层计算， [b, 256] => [b, 128]\n",
    "      h2 = h1 @ w2 + b2\n",
    "      h2 = tf.nn.relu(h2)\n",
    "      # 输出层计算， [b, 128] => [b, 10]\n",
    "      out = h2 @ w3 + b3\n",
    "\n",
    "      # 计算网络输出与标签之间的均方差， mse = mean(sum(y-out)^2)\n",
    "      # [b, 10]\n",
    "      loss = tf.square(y - out)\n",
    "      # 误差标量， mean: scalar\n",
    "      loss = tf.reduce_mean(loss)\n",
    "\n",
    "      # 自动梯度，需要求梯度的张量有[w1, b1, w2, b2, w3, b3]\n",
    "      grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "\n",
    "    # 梯度更新， assign_sub 将当前值减去参数值，原地更新\n",
    "    w1.assign_sub(lr * grads[0])\n",
    "    b1.assign_sub(lr * grads[1])\n",
    "    w2.assign_sub(lr * grads[2])\n",
    "    b2.assign_sub(lr * grads[3])\n",
    "    w3.assign_sub(lr * grads[4])\n",
    "    b3.assign_sub(lr * grads[5])\n",
    "\n",
    "  return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow的非線性寫法.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepoch:\u001b[39m\u001b[39m'\u001b[39m, epoch, \u001b[39m'\u001b[39m\u001b[39mloss:\u001b[39m\u001b[39m'\u001b[39m, loss)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n",
      "\u001b[1;32m/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow的非線性寫法.ipynb Cell 4\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m   grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, [w1, b1, w2, b2, w3, b3])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# 梯度更新， assign_sub 将当前值减去参数值，原地更新\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m w1\u001b[39m.\u001b[39massign_sub(lr \u001b[39m*\u001b[39;49m grads[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m b1\u001b[39m.\u001b[39massign_sub(lr \u001b[39m*\u001b[39m grads[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/p89_tensorflow%E7%9A%84%E9%9D%9E%E7%B7%9A%E6%80%A7%E5%AF%AB%E6%B3%95.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m w2\u001b[39m.\u001b[39massign_sub(lr \u001b[39m*\u001b[39m grads[\u001b[39m2\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1440\u001b[0m, in \u001b[0;36m_OverrideBinaryOperatorHelper.<locals>.r_binary_op_wrapper\u001b[0;34m(y, x)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[39m@traceback_utils\u001b[39m\u001b[39m.\u001b[39mfilter_traceback\n\u001b[1;32m   1436\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr_binary_op_wrapper\u001b[39m(y, x):\n\u001b[1;32m   1437\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39mNone\u001b[39;00m, op_name, [x, y]) \u001b[39mas\u001b[39;00m name:\n\u001b[1;32m   1438\u001b[0m     \u001b[39m# TODO(b/178860388): Figure out why binary_op_wrapper and\u001b[39;00m\n\u001b[1;32m   1439\u001b[0m     \u001b[39m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[39;00m\n\u001b[0;32m-> 1440\u001b[0m     y, x \u001b[39m=\u001b[39m maybe_promote_tensors(y, x, force_same_dtype\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1441\u001b[0m     \u001b[39mreturn\u001b[39;00m func(x, y, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:1373\u001b[0m, in \u001b[0;36mmaybe_promote_tensors\u001b[0;34m(force_same_dtype, *tensors)\u001b[0m\n\u001b[1;32m   1370\u001b[0m   dtype \u001b[39m=\u001b[39m tensors[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\n\u001b[1;32m   1371\u001b[0m   \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensors[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m   1372\u001b[0m     promoted_tensors\u001b[39m.\u001b[39mappend(\n\u001b[0;32m-> 1373\u001b[0m         ops\u001b[39m.\u001b[39;49mconvert_to_tensor(tensor, dtype, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m   1374\u001b[0m   \u001b[39mreturn\u001b[39;00m promoted_tensors\n\u001b[1;32m   1375\u001b[0m result_type \u001b[39m=\u001b[39m np_dtypes\u001b[39m.\u001b[39m_result_type(\n\u001b[1;32m   1376\u001b[0m     \u001b[39m*\u001b[39m[_maybe_get_dtype(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39mflatten(tensors)])\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1636\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1630\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\u001b[39m\"\u001b[39m\u001b[39mpack_eager_tensors\u001b[39m\u001b[39m\"\u001b[39m, [packed_tensor], tensors,\n\u001b[1;32m   1631\u001b[0m                         grad_fun)\n\u001b[1;32m   1633\u001b[0m   \u001b[39mreturn\u001b[39;00m packed_tensor\n\u001b[0;32m-> 1636\u001b[0m \u001b[39m@profiler_trace\u001b[39m\u001b[39m.\u001b[39mtrace_wrapper(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor\u001b[39m(value,\n\u001b[1;32m   1638\u001b[0m                       dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1639\u001b[0m                       name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1640\u001b[0m                       as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1641\u001b[0m                       preferred_dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1642\u001b[0m                       dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1643\u001b[0m                       ctx\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1644\u001b[0m                       accepted_result_types\u001b[39m=\u001b[39m(Tensor,)):\n\u001b[1;32m   1645\u001b[0m   \u001b[39m\"\"\"Implementation of the public convert_to_tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m   \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# step4 訓練所有epoch\n",
    "losses = []\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    loss = train_epoch(epoch, train_dataset, w1, b1, w2, b2, w3, b3, lr=0.001)\n",
    "    print('epoch:', epoch, 'loss:', loss)\n",
    "    losses.append(loss)\n",
    "\n",
    "x = [i for i in range(0, epochs)]\n",
    "# 绘制曲线\n",
    "plt.plot(x, losses, color='blue', marker='s', label='训练')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
