{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  tensorflow as tf\n",
    "import  os\n",
    "# 1 隱藏 INFO logs, 2 額外隱藏WARNING logs, 設置為3所有 ERROR logs也不顯示\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from    tensorflow import keras\n",
    "from    tensorflow.keras import layers\n",
    "import  numpy as np\n",
    "\n",
    "\n",
    "class Generator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # z: [b, 100] => [b, 3*3*512] => [b, 3, 3, 512] => [b, 64, 64, 3]\n",
    "        self.fc = layers.Dense(3*3*512)\n",
    "\n",
    "        self.conv1 = layers.Conv2DTranspose(256, 3, 3, 'valid')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv2 = layers.Conv2DTranspose(128, 5, 2, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "        self.conv3 = layers.Conv2DTranspose(3, 4, 3, 'valid')\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # [z, 100] => [z, 3*3*512]\n",
    "        x = self.fc(inputs)\n",
    "        x = tf.reshape(x, [-1, 3, 3, 512])\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "\n",
    "        #\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = self.conv3(x)\n",
    "        x = tf.tanh(x)\n",
    "        print(\"Generator call\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Discriminator(keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # [b, 64, 64, 3] => [b, 1]\n",
    "        self.conv1 = layers.Conv2D(64, 5, 3, 'valid')\n",
    "        self.conv2 = layers.Conv2D(128, 5, 3, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv3 = layers.Conv2D(256, 5, 3, 'valid')\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "\n",
    "        # [b, h, w ,c] => [b, -1]\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Dense(1)\n",
    "\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        x = tf.nn.leaky_relu(self.conv1(inputs))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "\n",
    "        # [b, h, w, c] => [b, -1]\n",
    "        x = self.flatten(x)\n",
    "        # [b, -1] => [b, 1]\n",
    "        logits = self.fc(x)\n",
    "        print(\"Discriminator call\")\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator call\n",
      "tf.Tensor(\n",
      "[[0.00307981]\n",
      " [0.08289697]], shape=(2, 1), dtype=float32)\n",
      "Generator call\n",
      "(2, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "d = Discriminator()\n",
    "g = Generator()\n",
    "\n",
    "x = tf.random.normal([2, 64, 64, 3])\n",
    "z = tf.random.normal([2, 100])\n",
    "\n",
    "prob = d(x)\n",
    "print(prob)\n",
    "x_hat = g(z)\n",
    "print(x_hat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_anime_dataset(img_paths, batch_size, resize=64, drop_remainder=True, shuffle=True, repeat=1):\n",
    "    # @tf.function\n",
    "    def _map_fn(img):\n",
    "        img = tf.image.resize(img, [resize, resize])\n",
    "        # img = tf.image.random_crop(img,[resize, resize])\n",
    "        # img = tf.image.random_flip_left_right(img)\n",
    "        # img = tf.image.random_flip_up_down(img)\n",
    "        img = tf.clip_by_value(img, 0, 255)\n",
    "        img = img / 127.5 - 1 #-1~1\n",
    "        return img\n",
    "\n",
    "    dataset = disk_image_batch_dataset(img_paths,\n",
    "                                          batch_size,\n",
    "                                          drop_remainder=drop_remainder,\n",
    "                                          map_fn=_map_fn,\n",
    "                                          shuffle=shuffle,\n",
    "                                          repeat=repeat)\n",
    "    img_shape = (resize, resize, 3)\n",
    "    len_dataset = len(img_paths) // batch_size\n",
    "\n",
    "    return dataset, img_shape, len_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def celoss_ones(logits):\n",
    "    return - tf.reduce_mean(logits)\n",
    "\n",
    "def celoss_zeros(logits):\n",
    "    return tf.reduce_mean(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(discriminator, batch_x, fake_image):\n",
    "\n",
    "    batchsz = batch_x.shape[0]\n",
    "\n",
    "    # [b, h, w, c]\n",
    "    t = tf.random.uniform([batchsz, 1, 1, 1])\n",
    "    # [b, 1, 1, 1] => [b, h, w, c]\n",
    "    t = tf.broadcast_to(t, batch_x.shape)\n",
    "\n",
    "    interplate = t * batch_x + (1 - t) * fake_image\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch([interplate])\n",
    "        d_interplote_logits = discriminator(interplate, training=True)\n",
    "    grads = tape.gradient(d_interplote_logits, interplate)\n",
    "\n",
    "    # grads:[b, h, w, c] => [b, -1]\n",
    "    grads = tf.reshape(grads, [grads.shape[0], -1])\n",
    "    gp = tf.norm(grads, axis=1) #[b]\n",
    "    gp = tf.reduce_mean( (gp-1)**2 )\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    # 1. treat real image as real\n",
    "    # 2. treat generated image as fake\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "\n",
    "    d_loss_real = celoss_ones(d_real_logits)\n",
    "    d_loss_fake = celoss_zeros(d_fake_logits)\n",
    "    gp = gradient_penalty(discriminator, batch_x, fake_image)\n",
    "\n",
    "    loss = d_loss_real + d_loss_fake + 10. * gp\n",
    "\n",
    "    return loss, gp\n",
    "\n",
    "\n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "\n",
    "    fake_image = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(fake_image, is_training)\n",
    "    loss = celoss_ones(d_fake_logits)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 64, 64, 3)\n",
      "Generator call\n",
      "Discriminator call\n",
      "Generator call\n",
      "Discriminator call\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan實戰.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m             \u001b[39mprint\u001b[39m(epoch, \u001b[39m'\u001b[39m\u001b[39md-loss:\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mfloat\u001b[39m(d_loss), \u001b[39m'\u001b[39m\u001b[39mg-loss:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mfloat\u001b[39m(g_loss),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mgp:\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mfloat\u001b[39m(gp))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m             \u001b[39m# z = tf.random.normal([100, z_dim])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m             \u001b[39m# fake_image = generator(z, training=False)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m             \u001b[39m# img_path = os.path.join('images', 'wgan-%d.png'%epoch)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m             \u001b[39m# save_result(fake_image.numpy(), 10, img_path, color_mode='P')\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m train_gan()\n",
      "\u001b[1;32m/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan實戰.ipynb Cell 9\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# train D\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     d_loss, gp \u001b[39m=\u001b[39m d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(d_loss, discriminator\u001b[39m.\u001b[39mtrainable_variables)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m d_optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(grads, discriminator\u001b[39m.\u001b[39mtrainable_variables))\n",
      "\u001b[1;32m/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan實戰.ipynb Cell 9\u001b[0m in \u001b[0;36md_loss_fn\u001b[0;34m(generator, discriminator, batch_z, batch_x, is_training)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m fake_image \u001b[39m=\u001b[39m generator(batch_z, is_training)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m d_fake_logits \u001b[39m=\u001b[39m discriminator(fake_image, is_training)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m d_real_logits \u001b[39m=\u001b[39m discriminator(batch_x, is_training)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m d_loss_real \u001b[39m=\u001b[39m celoss_ones(d_real_logits)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangjunyu/py_project/tensorflow_learn_book/x_p338_wgan%E5%AF%A6%E6%88%B0.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m d_loss_fake \u001b[39m=\u001b[39m celoss_zeros(d_fake_logits)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/keras/engine/base_layer.py:1041\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[39m# Accept NumPy and scalar inputs by converting to Tensors.\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, (\n\u001b[1;32m   1040\u001b[0m     tf\u001b[39m.\u001b[39mTensor, np\u001b[39m.\u001b[39mndarray, \u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m)) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m input_list):\n\u001b[0;32m-> 1041\u001b[0m   inputs \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_convert_numpy_or_python_types, inputs)\n\u001b[1;32m   1042\u001b[0m   input_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m   1044\u001b[0m \u001b[39m# Handle `mask` propagation from previous layer to current layer. Masks can\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[39m# be propagated explicitly via the `mask` argument, or implicitly via\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \u001b[39m# setting the `_keras_mask` attribute on the inputs to a Layer. Masks passed\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[39m# explicitly take priority.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    910\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    911\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    913\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    915\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/keras/engine/base_layer.py:3382\u001b[0m, in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_numpy_or_python_types\u001b[39m(x):\n\u001b[1;32m   3381\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mTensor, np\u001b[39m.\u001b[39mndarray, \u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m)):\n\u001b[0;32m-> 3382\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(x)\n\u001b[1;32m   3383\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1559\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1495\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   1496\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m   1498\u001b[0m     value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1499\u001b[0m   \u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \n\u001b[1;32m   1501\u001b[0m \u001b[39m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[39m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1559\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor_v2(\n\u001b[1;32m   1560\u001b[0m       value, dtype\u001b[39m=\u001b[39;49mdtype, dtype_hint\u001b[39m=\u001b[39;49mdtype_hint, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1565\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1564\u001b[0m   \u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1565\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor(\n\u001b[1;32m   1566\u001b[0m       value\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m   1567\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1568\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1569\u001b[0m       preferred_dtype\u001b[39m=\u001b[39;49mdtype_hint,\n\u001b[1;32m   1570\u001b[0m       as_ref\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1691\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1692\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[1;32m   1694\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1695\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1697\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1698\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     47\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras import layers, optimizers, datasets  # 导入 TF 子库\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()  # 加载数据集\n",
    "x = np.resize(x, (len(x),64, 64,3))\n",
    "x = x[:512]\n",
    "print(x.shape)\n",
    "db_iter = iter(x)\n",
    "def train_gan():\n",
    "    tf.random.set_seed(233)\n",
    "    np.random.seed(233)\n",
    "    assert tf.__version__.startswith('2.')\n",
    "\n",
    "\n",
    "    # hyper parameters\n",
    "    z_dim = 100\n",
    "    epochs = 3000000\n",
    "    batch_size = 512\n",
    "    learning_rate = 0.0005\n",
    "    is_training = True\n",
    "\n",
    "    generator = Generator() \n",
    "    generator.build(input_shape = (None, z_dim))\n",
    "    discriminator = Discriminator()\n",
    "    discriminator.build(input_shape=(None, 64, 64, 3))\n",
    "    z_sample = tf.random.normal([100, z_dim])\n",
    "\n",
    "\n",
    "    g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "    d_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for _ in range(5):\n",
    "            batch_z = tf.random.normal([batch_size, z_dim])\n",
    "            batch_x = next(db_iter)\n",
    "            batch_x = np.resize(batch_x,(1, batch_x.shape[0], batch_x.shape[1], batch_x.shape[2]))\n",
    "            \n",
    "            batch_x = np.array(batch_x, dtype = 'float64') \n",
    "\n",
    "            # train D\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss, gp = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "            grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "        \n",
    "        batch_z = tf.random.normal([batch_size, z_dim])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "        grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, 'd-loss:',float(d_loss), 'g-loss:', float(g_loss),\n",
    "                  'gp:', float(gp))\n",
    "\n",
    "            # z = tf.random.normal([100, z_dim])\n",
    "            # fake_image = generator(z, training=False)\n",
    "            # img_path = os.path.join('images', 'wgan-%d.png'%epoch)\n",
    "            # save_result(fake_image.numpy(), 10, img_path, color_mode='P')\n",
    "\n",
    "train_gan()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:05:16) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
